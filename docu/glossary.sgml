<glossary>

  <glossentry id="ARP">
    <glossterm>ARP</glossterm>
    <glosssee otherterm="ARPfull"/>
  </glossentry>

  <glossentry id="ARPfull">
    <glossterm>Address Resolution Protocol</glossterm>
    <glossdef>
      <para>
	A sending host decides, through a protocols routing mechanism, that it
	wants to transmit to a target host located some place on a connected
	piece of a physical network. To actually transmit the hardware packet
	usually a hardware address must be generated. In the case of Ethernet
	this is 48 bit Ethernet address. The addresses of hosts within a
	protocol are not always compatible with the corresponding hardware
	address (being different lengths or values).
      </para>
      <para>
	The Address Resolution Protocol (ARP) is used by the sending host in
	order to resolv the Ethernet address of the target host from its IP
	address. It is described in the <ulink
	  url="http://www.faqs.org/rfcs/rfc826.html">RFC 826</ulink>. The ARP
	is part of the TCP/IP protocol family.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="DMA">
    <glossterm>DMA</glossterm>
    <glosssee otherterm="DMAfull"/>
  </glossentry>

  <glossentry id="DMAfull">
    <glossterm>Direct Memory Access</glossterm>
    <glossdef>
      <para>
	In the old days devices within a computer where not able to put data
	into memory on their own but the CPU had to fetch it from them and to
	store it to the final destination manually.
      </para>
      <para>
	Nowadays devices as Ethernet cards, harddisk controllers, Myrinet cards
	etc. are capable to store chunks of data into memory on their
	own. E.g. a disk controller is told to fetch an amount of memory from a
	hard disk and to store it to a given address. The rest of the jobs is
	done by this controller without producing further load to the CPU.
      </para>
      <para>
	Obviously this concept helps to disburden the CPU from work which is
	not its first task and thus gives more power to solve the actual
	application.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="forwarder">
    <glossterm>forwarder</glossterm>
    <glosssee otherterm="forwarderfull"/>
  </glossentry>

  <glossentry id="logger">
    <glossterm>logger</glossterm>
    <glosssee otherterm="loggerfull"/>
  </glossentry>

  <glossentry id="MCP">
    <glossterm>MCP</glossterm>
    <glosssee otherterm="MCPfull"/>
  </glossentry>

  <glossentry id="MCPfull">
    <glossterm>Myrinet Control Program</glossterm>
    <glossdef>
      <para>
	The program controlling the Myrinet card. It is executed by the LanAI
	processor residing on the Myrinet card and thus creates almost no load
	on the node's main processor.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="NIC">
    <glossterm>NIC</glossterm>
    <glosssee otherterm="NICfull"/>
  </glossentry>

  <glossentry id="NICfull">
    <glossterm>Network Interface Card</glossterm>
    <glossdef>
      <para>
	The physical device which connects a computer to a network. Examples
	are Ethernet cards (which are nowadays often found to be on board) or
	Myrinet cards.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="task">
    <glossterm>parallel task</glossterm>
    <glossdef>
      <para>
	A bunch of <link linkend="process">processes</link> distributed within
	the cluster forming a parallel application. E.g. a MPI program running
	on several nodes of a cluster can only act as a whole but consists of
	individual processes on each node. &ps; knows anout their
	interrelationship and can handle them as a distributed parallel task
	running on the cluster.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="loggerfull">
    <glossterm>&ps; logger</glossterm>
    <glossdef>
      <para>
	The counterpart to the <link linkend="forwarderfull">&ps;
	  forwarder</link>. It receives the all the output collected by the
	forwarder processes and puts it their destination. Furthermore input to
	the &ps; task is forwarded to a specific process.
      </para>
      <para>
	The first process of the task started usually converts to the logger
	processes after spawning all the other processes of 
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="forwarderfull">
    <glossterm>&ps; forwarder</glossterm>
    <glossdef>
      <para>
	Collects output written by &ps; controlled processes to
	<filename>stdout</filename> or <filename>stderr</filename> and sends it
	to the <link linkend="loggerfull">&ps; logger</link>.
      </para>
      <para>
	Furthermore the forwareder controls the process and sends information
	about its exit status when it finishes to the local daemon.
      </para>
    </glossdef>
  </glossentry>

  <glossentry id="process">
    <glossterm>process</glossterm>
    <glossdef>
      <para>
	The atomic part of a <link linkend="task">parallel task</link>. A
	process is at first a standard Unix process. Since &ps; knows about its
	membership in a parallel task, it can be handled in a peculiar way if
	a events takes place on some other node (e.g. another process of the
	task dies unexpectedly, a signal is send to the task, etc.).
      </para>
    </glossdef>
  </glossentry>

</glossary>
  <!-- Keep this comment at the end of the file
  Local variables:
  mode: xml
  sgml-omittag:nil
  sgml-shorttag:nil
  sgml-namecase-general:nil
  sgml-general-insert-case:lower
  sgml-minimize-attributes:nil
  sgml-always-quote-attributes:t
  sgml-indent-step:2
  sgml-indent-data:t
  sgml-parent-document:("adminguide.xml" "book" "book" ("title" "bookinfo"))
  sgml-exposed-tags:nil
  sgml-local-catalogs:nil
  sgml-local-ecat-files:nil
  End:
  -->
