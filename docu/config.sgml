<chapter id="configuration">
  <title>Configuration</title>

  <para>
    After installing the &ps; software successfully few modification to
    the configuration file <xref linkend="parastation_conf"/> have to be made
    in order to enable &ps; on the local cluster.
  </para>

  <section id="config_ps">
    <title>Configuration of the &ps; system</title>
    <para>
      Within this section the basic configuration procedure needed to enable
      &ps; is discussed. Primarily the configuration work reduces to the
      editing of the configuration file <filename>parastation.conf</filename>,
      which is basically located in <filename>/etc</filename>.
    </para>
    <para>
      Usually you will find in <filename>/etc</filename> only a symbolic link
      pointing to
      <filename>/opt/parastation/config/parastation.conf</filename>, which is
      normally mounted via NFS on the nodes. This allows in an easy way the
      centralized storing of the configuration file in order to reduce the
      effort that has to be made to modify this file consistently on all nodes.
    </para>
    <para>
      Within this section only the fundamental parameters which are necessary
      to make &ps; run on a specific cluster are discussed. A detailed
      description of all possible parameters that can be tuned within the
      configuration file can be found within the <xref
	linkend="parastation_conf"/> manual page.
    </para>
    <para>
      It is considered that &ps; is installed in a centralized fashion to the
      default location <filename>/opt/parastation</filename> and mounted to
      this location on all the nodes. In case of a distributed installation it
      has to be guaranteed explicitely that all &ps; daemons <xref
	linkend="psid"/> see configuration files with consistent content. This
      may be ensured by editing the <filename>parastation.conf</filename> file
      on one node and distribute the adapted file in a more or less automatized
      way towards all the nodes.
    </para>
    <para>
      The distributed configuration files may explicitely replace the symbolic
      link <filename>/etc/parastation.conf</filename>, which of course is also
      possible for the centralized installation, although not recommended.
      Another possibility for the distributed installation to keep the symbolic
      link and to modify the file the link is pointing to distributedly. Keep
      in mind that this has to be done on <emphasis role="bold">all</emphasis>
      nodes.
    </para>
    <para>
      If &ps; is installed in the recommended way (i.e. centralized
      installation to <filename>/opt/parastation</filename>) only the following
      steps have to be executed on the NFS server:
    </para>
    <orderedlist>
      <listitem>
	<para><emphasis role="bold">Copy template</emphasis></para>
	<para>
	  Change to the configuration directory
	  <filename>/opt/parastation/config</filename> and copy the template
	  configuration file <filename>parastation.conf.tmpl</filename> to the
	  actual position <filename>parastation.conf</filename>.
	</para>
	<para>
	  The template file contains all possible parameters understood by the
	  &ps; daemon <xref linkend="psid"/>. Most of these parameters are set
	  to their default value and commented out. Only those that have to be
	  modified in order to addapt &ps; to the local cluster are enabled.
	  Additionally all parameters are accompanied by a describing comment.
	  A detailed description of all the parameters can be found in the
	  <xref linkend="parastation_conf"/> manual page.
	</para>
	<para>
	  The template file is a good basis in order to create a working
	  configuration of &ps; for your cluster.
	</para>
      </listitem>
      <listitem>
	<para>
	  <emphasis role="bold"><command>Number of nodes</command></emphasis>
	</para>
	<para>
	  Adjust the <command>NrOfNodes</command> parameter to the actual value
	  used in your cluster. Consider that the front end machine is part of
	  the cluster. E.g. if your cluster contains 8 nodes with a fast
	  interconnect plus a front end machine then
	  <command>NrOfNodes</command> has to be set to 9 if a &ps; daemon
	  <xref linkend="psid"/> should run on the front end machine in
	  order to allow the start of parallel jobs from there.
	</para>
      </listitem>
      <listitem>
	<para>
	  <emphasis role="bold"><command>HWType</command></emphasis>
	</para>
	<para>
	  In order to tell &ps; which kind of communication hardware should be
	  used modify the <command>HWType</command> parameter. In the case of a
	  Myrinet cluster, i.e. the version of &ps; used is ParaStation 3, this
	  has to be set to:
	</para>
	<programlisting>	HWType myrinet</programlisting>
	<para>
	  If the cluster to be configured uses Ethernet of any flavour and
	  ParaStation FE is the software of choice you will want to set this
	  parameter to:
	</para>
	<programlisting>	HWType ethernet</programlisting>
	<!-- @todo ParaStation 4 -->
      </listitem>
      <listitem>
	<para>
	  <emphasis role="bold"><command>Nodes</command></emphasis>
	</para>
	<para>
	  Furthermore &ps; has to be told which nodes are contained in the
	  cluster. The usual way of using the <command>Nodes</command>
	  parameter is the environment mode, that is allready enabled in the
	  template file.
	</para>
	<para>
	  For each cluster node defined within the <command>Nodes</command>
	  environment at least the hostname of the node and the &ps; ID of this
	  node have to be given. The general syntax of the
	  <command>Nodes</command> environment is one entry per line. Each
	  entry has the form
	</para>
	<programlisting>	<replaceable>hostname</replaceable> <replaceable>id</replaceable> <optional><option>HWType-entry</option></optional> <optional><option>hasIP-entry</option></optional> <optional><option>starter-entry</option></optional></programlisting>
	<para>
	  This will register the node
	  <parameter><replaceable>hostname</replaceable></parameter> to the
	  &ps; system with the &ps; ID
	  <parameter><replaceable>id</replaceable></parameter>. The &ps; ID has
	  to be an integer number between 0 and <command>NrOfNodes</command>-1.
	</para>
	<para>
	  The optional parameters <command>HWType</command>,
	  <command>hasIP</command> and <command>starter</command> may be
	  ignored for now. For a detailed description of these parameters refer
	  to the <xref linkend="parastation_conf"/> manual page.
	</para>
	<para>
	  Usually the nodes will be enlisted ordered by increasing &ps; ID,
	  beginning with 0 for the first node. If a front end machine exists
	  and furthermore should be integrated into the &ps; system, it usually
	  acts as the last node of the &ps; system, i.e. has the &ps; ID
	  <command>NrOfNodes</command>-1.
	</para>
	<para>
	  The described convention is mainly due to the routing used within
	  Myrinet clusters. While on a Ethernet cluster the mapping between
	  hostnames and &ps; ID is completely unrestricted, there are
	  constraints concerning this mapping in the Myrinet case. Actually in
	  order to use standard routing files the &ps; ID of a specific node
	  depends on the port of the Myrinet switch it is connected to. This
	  will be discussed in further detail within the next section.
	</para>
      </listitem>
      <listitem>
	<para>
	  <emphasis role="bold"><command>LicenseServer</command></emphasis>
	</para>
	<para>
	  This parameter tells &ps; on which node the &ps; license daemon <xref
	    linkend="psld"/> should be started. Remember
	  that &ps; has to be installed on this node, too.
	</para>
	<para>
	  For clusters with an existing front end machine usually the front end
	  will run the license daemon. Otherwise the machine which acts as the
	  node with &ps; ID 0 will normally adopt this tasks.
	</para>
      </listitem>
      <listitem>
	<para>
	  <emphasis role="bold">License key</emphasis>
	</para>
	<para>
	  If not already done, a license key has to be obtained now. It is not
	  possible to run &ps; without a valid license key. To obtain a license
	  key please contact <email>license@par-tec.com</email>.
	</para>
	<para>
	  You will get the license file by email. Save the license key to
	  <filename>/opt/parastation/config/license</filename>. This is the
	  default location where the &ps; daemon <xref linkend="psid"/> is
	  expecting the license key. Please consult the manual page of the &ps;
	  configuration file <xref linkend="parastation_conf"/> on how to
	  modify this default location.
	</para>
      </listitem>
    </orderedlist>
    <para>
      In the case of a Ethernet cluster running ParaStation FE the
      configuration procedure is finished now and you can proceed with <xref
	linkend="testing"/>. On Myrinet clusters some further parameters
      concerning the Myrinet configuration have to be set up. These will be
      discussed in
      <xref linkend="myrinet_setup"/> and <xref linkend="ip_over_myrinet"/>.
    </para>
  </section>

  <section id="myrinet_setup">
    <title>Further parameters on Myrinet clusters</title>
    <para>
      The following parameters only make sense if a Myrinet cluster is going to
      be configured.
    </para>
    <orderedlist continuation="continues">
      <listitem>
	<para>
	  <emphasis role="bold"><command>MyrinetModule</command></emphasis>
	</para>
	<para>
	  Tell &ps; where to find the kernel module which will run the Myrinet
	  card.
	</para>
	<para>
	  The parameter set may be a absolute or relative path. Relative paths
	  are looked up relative to
	  <filename><replaceable>InstallDir</replaceable>/bin/modules</filename>
	  and <filename><replaceable>InstallDir</replaceable></filename> in
	  this order. 
	</para>
	<para>
	    <filename><replaceable>InstallDir</replaceable></filename> defaults
	  to <filename>/opt/parastation</filename> or may be set using the
	  <command>InstallDir</command> parameter. This is described in detail
	  within the <xref linkend="parastation_conf"/> manual page.
	</para>
      </listitem>

      <listitem>
	<para>
	  <emphasis role="bold"><command>RoutingFile</command></emphasis>
	</para>
	<para>
	  Myrinet is a source routed network. This means that each <link
	    linkend="NIC">NIC</link> has to know which way a data packet it
	  wants to send has to take through the switches in order to arrive at
	  the correct destination. I.e. each packet must contain the full
	  routing information. Of course this routing information depends
	  substantially on the network topology of the cluster. For
	  flexibilities sake this information is not hardcoded within the
	  kernel module as it was in ParaStation2 but will be read during run
	  time from an extra configuration file.
	</para>
	<para>
	  This parameter will tell &ps; which routing information it has to use
	  for correct delivery of packets via Myrinet.
	</para>
	<para>
	  In principle any topology of the network is supported just by editing
	  the routing information stored within the configuration file. In fact
	  there are tools within the &ps; distribution to construct this files
	  in an automatized way. This will be discussed in detail in
	  <xref linkend="setup_route"/>.
	</para>
	<note>
	  <para>
	      The discussion of preconfigured routing files reduces to Myrinet
	    2000 switches. If you use older Myrinet hardware as a fast
	    interconnect within your cluster, please proceed with <xref
		linkend="setup_route"/> to create the routing file on your own
	    or contact <ulink url="http://www.par-tec.com">ParTec AG</ulink>
	    for further support on setting up the routing.
	  </para>
	  <para>
	      Furthermore there are no routing files for clusters with more
	    than 128 nodes. These have to be created in the way described in
	      <xref linkend="setup_route"/>, too.
	  </para>
	</note>
	<para>
	  For most of the common network topologies supported by Myrinet an
	  easy to use routing file already exists. For all these routing files
	  it is assumed that the nodes are connected to the Myrinet switch in
	  the following way: Starting with node 0 (i.e. the node with &ps; ID
	  0) at the upper right corner of the switch, the nodes are connected
	  in ascending order of &ps; ID from right to left. If the top level
	  board of the switch is completely filled, proceed with the next board
	  again connecting from the right to the left and so on.
	</para>
	<para>
	  If the connection of the nodes to the Myrinet switch uses this
	  convention, one the following standard routing files can be used:
	</para>
	<variablelist>
	  <varlistentry>
	    <term><filename>M3E16.route</filename></term>
	    <listitem>
	      <para>
		Use this routing file if your cluster has a 16 node switch,
		i.e. a switch with two line cards.
	      </para>
	    </listitem>
	  </varlistentry>

	  <varlistentry>
	    <term><filename>M3E16reverse.route</filename></term>
	    <listitem>
	      <para>
		This routing file is kind of special. It also supports a 16
		node switch, i.e. a switch with two line cards, but with
		reverse cabling. This means node 0 is connected in the lower
		left edge of the switch. Further nodes are connected left to
		right proceeding with the upper line board when the lowest is
		full.
	      </para>
	    </listitem>
	  </varlistentry>

	  <varlistentry>
	    <term><filename>M3E32.route</filename></term>
	    <listitem>
	      <para>
		Use this routing file if your cluster has a 32 node switch,
		i.e. a switch with four line cards and cabling conventions
		describe above.
	      </para>
	    </listitem>
	  </varlistentry>

	  <varlistentry>
	    <term><filename>M3E64.route</filename></term>
	    <listitem>
	      <para>
		This routing file is for clusters with a 64 node switch, i.e. a
		switch with eight line cards.
	      </para>
	    </listitem>
	  </varlistentry>

	  <varlistentry>
	    <term><filename>M3E128.route</filename></term>
	    <listitem>
	      <para>
		Use this routing file if your cluster has a 128 node switch,
		i.e. a switch with sixteen line cards.
	      </para>
	    </listitem>
	  </varlistentry>
	</variablelist>
	<para>
	  All these files are located in the directory
	  <filename>/opt/parastation/config</filename>.
	</para>
	<para>
	  In order to tell &ps; which routing file is the appropriate one the
	  <command>RoutingFile</command> parameter can be used. This parameter
	  set may be a absolute or relative path. Relative paths are looked up
	  relative to
	  <filename><replaceable>InstallDir</replaceable>/config</filename> and
	  <filename><replaceable>InstallDir</replaceable></filename> in this
	  order. 
	</para>
	<para>
	    <filename><replaceable>InstallDir</replaceable></filename> defaults
	  to <filename>/opt/parastation</filename> or may be set using the
	  <command>InstallDir</command> parameter. This is described in detail
	  within <xref linkend="parastation_conf"/>.
	</para>
      </listitem>
    </orderedlist> 
  </section>

  <section id="ip_over_myrinet">
    <title>IP over Myrinet</title>
    <para>
      This section describes the necessary configuration in order to obtain a
      working IP over Myrinet setup. If you are not interested in having such
      type of setup, you can skip this section and proceed with <xref
	linkend="testing"/>
    </para>
    <para>
      IP over Myrinet is intended mainly for applications using TCP or UDP
      sockets which cannot be modified in order to make use of the more
      efficient MPI or the PSPort interface. Be aware of the fact that IP over
      Myrinet is quite unefficient, since the overhead of the whole TCP/IP
      stack has to be taken into account. On the other hand it is much faster
      than TCP/IP over fast Ethernet anyway.
    </para>
    <para>
      To enable IP over Myrinet three different parameters might have to be set
      within the &ps; configuration file <filename>parastation.conf</filename>:
      <command>IPModule</command>, <command>IPPrefix</command> and
      <command>IPPrefixLen</command>. The purpose of the two latter ones can be
      understood after going a little bit into detail.
    </para>
    <para>
      As already discussed, since Myrinet is a source routed network, each
      <link linkend="NIC">NIC</link> has to know which way a data packet is is
      going to send has to take through the switches in order to arrive at the
      correct destination. This is also true for IP packets sent over Myrinet.
    </para>
    <para>
      IP packets usually do not contain routing information but only the
      destination IP address. This address will be resolved to a destination
      hardware address via an <link linkend="ARP">ARP</link> call. Then the
      packet will be send to this hardware address. An Ethernet switch will
      deliver the packet to the right line on basis of this hardware address.
    </para>
    <para>
      In principle IP over Myrinet can work the same way. On the other hand
      every node of a Myrinet cluster running &ps; already has a unique number,
      the &ps; ID. Obviously this ID does not have the form of an IP address,
      but it can serve as a basis to create one.
    </para>
    <para>
      Within &ps; exist two distinct ways to assign IP addresses to the Myrinet
      cards on the different nodes. The first one is to create a unique IP
      address on basis of the &ps; ID and a prefix that can be parameterized
      within the configuration file. The second one is to explicitely assign an
      IP address to each Myrinet card. The latter uses the
      <option>MyrinetIP</option> option of the <command>Nodes</command>
      parameter.
    </para>
    <para>
      Both ans&auml;tze will be discussed in detail in the next two
      subsections.
    </para>
    <section>
      <title>IP address from prefix</title>
      <para>
	The first concept used by &ps; is the following: You can define a
	prefix and its lenght which are identical for all participating nodes.
	These build the most signigicant bits of the IP address. Then the IP
	address is filled up with the &ps; ID to create a valid
	address<footnote>
	  <para>
	    This is not completely true. Since the IP address with all bits 0
	    in the subnet part defined by the netmask has a special meaning,
	    the &ps; ID cannot be used one to one but an offset of 1 has to be
	    taken into account.
	  </para>
	</footnote>.
      </para>
      <example>
	<title></title>
	<para>
	  Let the prefix be '192.168.16.0' and the prefix length 20 bits, then
	  the Myrinet card in the node with &ps; ID 0 will get IP address
	  192.168.16.1, the one in node 5 will get 192.168.16.6 and so on.
	</para>
      </example>
      <para>
	Following this short excursion lets discuss the actual parameters. In
	order to enable IP over Myrinet in your &ps; cluster using the prefix
	style configuration, the following three parameters have to be set
	within the &ps; configuration file
	<filename>/etc/parastation.conf</filename>:
      </para>
      <orderedlist continuation="continues">
	<listitem>
	  <para>
	    <emphasis role="bold"><command>IPModule</command></emphasis>
	  </para>
	  <para>
	    Tell &ps; where to find the kernel module which enables IP over
	    Myrinet.
	  </para>
	  <para>
	    The parameter set may be a absolute or relative path. Relative
	    paths are looked up relative to
	    <filename><replaceable>InstallDir</replaceable>/bin/modules</filename> 
	    and <filename><replaceable>InstallDir</replaceable></filename> in
	    this order. 
	  </para>
	  <para>
	  <filename><replaceable>InstallDir</replaceable></filename> defaults
	    to <filename>/opt/parastation</filename> or may be set using the
	    <command>InstallDir</command> parameter. This is described in
	    detail within the <xref linkend="parastation_conf"/> manual page.
	  </para>
	</listitem>

	<listitem>
	  <para>
	    <emphasis role="bold"><command>IPPrefix</command></emphasis>
	  </para>
	  <para>
	    This parameter tells &ps; which prefix to use in order to create an
	    IP addresses from the &ps; ID. It is expected to follow the
	    ordinary dot notation of IP addresses, e.g.
	    <quote>192.168.16.0</quote>.
	  </para>
	</listitem>

	<listitem>
	  <para>
	    <emphasis role="bold"><command>IPPrefixLen</command></emphasis>
	  </para>
	  <para>
	    Tell &ps; how many bits of the <command>IPPrefix</command>
	    parameter to use to create IP addresses. The default value is 20.
	  </para>
	</listitem>
      </orderedlist>
    </section>
    <section>
      <title>Explicit IP addresses</title>
      <para>
	Within the second concept implemented in &ps; the IP address of each
	Myrinet card can be choosen independently. In order to use this style
	Myrinet over IP setup, the <option>MyrinetIP</option> option of the
	<command>Nodes</command> parameter has to be used.
      </para>
      <para>
	This makes the <command>Nodes</command> entries within the ParaStation
	configuration file <filename>/etc/parastation.conf</filename> look like
	as follows:
      </para>
      <programlisting>
	Nodes {
	   node1 0 MyrinetIP myri1
	   node2 1 MyrinetIP 192.168.17.5
	   frontend 3 hw none
	}
      </programlisting>
      <para>
	In order to make this setup work, <replaceable>node1</replaceable>,
	<replaceable>node2</replaceable>, <replaceable>myri1</replaceable> and
	<replaceable>frontend</replaceable> of course have to be resolvable
	hostnames.
      </para>
      <para>
	This will setup the Myrinet card on <replaceable>node1</replaceable> to
	the IP address corresponding to <replaceable>myri1</replaceable> and
	the one on <replaceable>node2</replaceable> to 192.168.17.5. Here the
	frontend is supposed to have no Myrinet at all.
      </para>
    </section>
  </section>

  <section id="testing">
    <title>Testing the installation</title>
    <para>
      If everything went fine, you are ready to test &ps; now. On one of the
      nodes do 
    </para>
    <programlisting>	/opt/parastation/bin/psiadmin -c "status"</programlisting>
    <para>
      and repeat this command until all nodes are up. While doing so, you use
      the first &ps; command: <command>psiadmin</command>. Here it is used in
      the single command mode requesting the status of all nodes again and
      again. At the same time within each startup og
      <command>psiadmin</command> the local &ps; daemon is connected. While
      being connected the daemon will try to start all other daemons not yet
      up. The &ps; administration tool is described in detail in the
      corresponding manual page <xref
	linkend="psiadmin"/>.
    </para>
    <para>
      Alternatively you can continuously monitor the &ps; daemon using the
      <command>mlisten</command> tool, which is described the <xref
	linkend="mlisten"/> manual page. Then use the
      <command>psiadmin</command> in the interactive mode and use its
      <command>add</command> command to start all other nodes.
    </para>
    <para>
      If after a minute some nodes are still not up have a look at the nodes
      <filename>/var/log/messages</filename> file to get a clue what went
      wrong.
    </para>
    <para>
      When all nodes are up you can start
    </para>
    <programlisting>	/opt/parastation/bin/test_nodes -np <replaceable>nodes</replaceable></programlisting>
    <para>
      where <replaceable>nodes</replaceable> has to be replaced by the actual
      number of Myrinet nodes within your cluster. After a while a result like
    </para>
    <programlisting>
---------------------------------------
Master node 0
Process 0-31 to 0-31 ( node 0-31 to 0-31 ) OK
All connections ok

PSIlogger: done
    </programlisting>
    <para>
      should appear. Of course the '31' will be replace by a number depending
      on the number of nodes you have, i.e. <replaceable>nodes</replaceable>-1.
    </para>
    <para>
      If something went wrong, <command>test_nodes</command> may give
      continuously results like
    </para>
    <programlisting>
---------------------------------------
Master node 0
Process 0-2,4-6 to 0-7 ( node 0-2,4-6 to 0-7 ) OK
Process 3 to 0-6 ( node 3 to 0-6 ) OK
Process 7 to 0-2,4-7 ( node 7 to 0-2,4-7 ) OK
    </programlisting>
    <para>
      This indicates that either your routing setup or your Myrinet cabling
      might be wrong. As a first guess start with testing the cabling. From the
      output of the above example you can guess that a problem exists on the
      connection of node 3 to node 7. As a result check this connections.
    </para>
    <para>
      A detailed description of <command>test_nodes</command> can be found
      within the corresponding manual page <xref linkend="test_nodes"/>.
    </para>
  </section>


  <!--
  <section id="embed">
    <title>Embed &ps;</title>
    <para></para>

    <section>
      <title>Integration with OpenPBS</title>
      <para>
	ToDo
      </para>
    </section>

    <section>
      <title>Integration with LSF</title>
      <para>
	ToDo
      </para>
    </section>
  </section>
  -->

  <section id="setup_route">
    <title>Setting up routing on customized network topologies</title>
    <para>
      <anchor id="embed"/>
      If your network topology is special and not covered within the standard
      routing files or if you are using the old Myrinet hardware (i.e. pre
      Myrinet 2000 hardware), you might have to create a a custimized routing
      file in order to setup &ps; correctly.
    </para>
    <para>
      This section covers the creation of a customized routing file and thus is
      only interesting in the case that the network topology of your cluster is
      not covered by the standard routing tables within the standard
      ParaStation distribution. Otherwise you may savely skip this section.
    </para>
    <para>
      The creation of the routing file is a two step procedure, starting with a
      scan of your network to create a file containing the topology information
      of the network and continuing with the creation of the actual routing
      information.
    </para>
    <para>
      In order to enable the &ps; scanning tool <xref linkend="psscan"/> to
      uncover the network topology some setup of the Myrinet hardware has to be
      done. I.e. the <link linkend="MCP">MCP</link> has to be started on the
      Myrinet cards. This status can be reached by following the direction of
      <xref linkend="config_ps"/> and <xref linkend="myrinet_setup"/>,
      obviously without telling the &ps; daemon the correct routing
      information. Instead just use one of the given routing files, e.g.
      <filename>M3E16.route</filename> for the <command>RoutingFile</command>
      parameter.
    </para>
    <para>
      Then start up all daemons following the steps in <xref
	linkend="testing"/>. Of course actual testing of the Myrinet using the
      <command>test_nodes</command> program cannot yet be done. It is fully
      sufficient if all &ps; daemons are up (test this using the
      <command>status</command> directive withing the &ps; administration tool
      <xref
	linkend="psiadmin"/>) and all daemons have found the local Myrinet card
      and activated (test this within <xref linkend="psiadmin"/> using the
      <command>status <option>hw</option></command> directive).
    </para>
    <para>
      After &ps; is setup to this stage, login to any node connected to
      the Myrinet and become <quote>root</quote>. Now the &ps; scanning
      tool <xref linkend="psscan"/> can be started. Redirect its output into a
      file, say <filename>network.psmap</filename>:
    </para>
    <programlisting>	/opt/parastation/bin/psscan &gt; network.psmap</programlisting>
    <para>
      A detailed description of the scanning tool and the format of the
      topology information produced can be found within the corresponding
      manual page <xref linkend="psscan"/>.
    </para>
    <para>
      In a second step the topology information has to be transformed into a
      routing table that can be handled by the <link linkend="MCP">MCP</link>.
      This is the purpose of the <xref linkend="psroute"/> tool. Considering
      the topology information in the file <filename>network.psmap</filename>,
      it is invoked by:
    </para>
    <programlisting>	/opt/parastation/bin/psroute &lt; network.psmap &gt; network.route</programlisting>
    <para>
      The new routing table, hand-crafted to your actual network setup will, be
      written to standard out and thus be saved to
      <filename>network.route</filename> by the above command invocation. The
      format of the routing table information with the routing file is
      discussed in detail within the manual page <xref linkend="psroute"/>.
    </para>
    <para>
      Now you have to stop the &ps; system using the
      <command>shutdown</command> directive of the &ps; administration tool
      <xref linkend="psiadmin"/>. Afterwards you can copy the routing file to
      the <filename>config</filename> directory within the &ps; tree
      <filename>/opt/parastation</filename> and promote this information to the
      &ps; daemon <xref linkend="psid"/> using the
      <command>RoutingFile</command> parameter within the configuration file
      <xref linkend="parastation_conf"/>.
    </para>
    <para>
      Proceed with testing the ParaStation system as discussed in <xref
	linkend="testing"/>.
    </para>
  </section>

</chapter>
  <!-- Keep this comment at the end of the file
  Local variables:
  mode: xml
  sgml-omittag:nil
  sgml-shorttag:nil
  sgml-namecase-general:nil
  sgml-general-insert-case:lower
  sgml-minimize-attributes:nil
  sgml-always-quote-attributes:t
  sgml-indent-step:2
  sgml-indent-data:t
  sgml-parent-document:("adminguide.xml" "book" "book" ("title" "bookinfo"))
  sgml-exposed-tags:nil
  sgml-local-catalogs:nil
  sgml-local-ecat-files:nil
  End:
  -->
