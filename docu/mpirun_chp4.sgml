<refentry id="mpirun_chp4">
  <refmeta>
    <refentrytitle>mpirun_chp4</refentrytitle>
    <manvolnum>1</manvolnum>
  </refmeta>

  <refnamediv>
    <refname>mpirun_chp4</refname>
    <refpurpose>
      run a MPIch/P4 MPI program on a &ps; cluster
    </refpurpose>
  </refnamediv>

  <refsynopsisdiv>
    <cmdsynopsis>
      <command>mpirun_chp4</command>
      <arg>-?Vv</arg>
      <arg choice="plain">-np <replaceable>nodes</replaceable></arg>
      <group>
	<arg>-nodes <replaceable>nodelist</replaceable></arg>
	<arg>-hosts <replaceable>hostlist</replaceable></arg>
	<arg>-hostfile <replaceable>hostfile</replaceable></arg>
      </group>
      <arg>-sort <group choice="req">
	  <arg>proc</arg>
	  <arg>load</arg>
	  <arg>proc+load</arg>
	  <arg>none</arg>
	</group>
      </arg>
      <arg>-all-local</arg>
      <arg>-inputdest <replaceable>dest</replaceable></arg>
      <arg>-sourceprintf</arg>
      <arg>-rusage</arg>
      <arg>-exports <replaceable>envlist</replaceable></arg>
      <arg>-keep_pg</arg>
      <arg>-leave_pg</arg>
      <arg>--usage</arg>
      <arg choice="plain">program</arg>
      <arg rep="repeat">arg</arg>
    </cmdsynopsis>
  </refsynopsisdiv>

  <refsect1>
    <title>Description</title>
    <para>
      <command>mpirun_chp4</command> is a tool that enables MPIch/P4 programs
      to run on a &ps; cluster under control of the &ps; management facility.
      Within &ps; the startup of parallel jobs is handled as described within
      the <xref linkend="spawning"/> manual page. The spawning mechanism is
      either steered by environment variables, which are described in detail
      within <xref linkend="environment"/>, or via options to the
      <command>mpirun_chp4</command> command. In fact these do nothing but
      setting the corresponding environment variables.
    </para>
    <para>
      <command>mpirun_chp4</command> typically works like this:
    </para>
    <programlisting>	mpirun_chp4 -np <replaceable>num</replaceable> <replaceable>prog</replaceable> <optional><replaceable>args</replaceable></optional>
    </programlisting>
    <para>
      This will startup the parallel MPIch/P4 program <command>prog</command>
      on <replaceable>num</replaceable> nodes of the cluster.
      <replaceable>args</replaceable> are optional argument which will be
      passed to each instance of <command>prog</command>.
    </para>
  </refsect1>

  <refsect1>
    <title>Options</title>
    <variablelist>
      <varlistentry>
	<term>
	  <option>-np <replaceable>nodes</replaceable></option>
        </term>
	<listitem>
	  <para>Specify the number of processors to run on.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-nodes <replaceable>nodelist</replaceable></option>
	</term>
	<listitem>
	  <para>Define the nodes which will build the partition of the &ps;
	    cluster used in order to spawn new processes.
	  </para>
	  <para>
	    <replaceable>nodelist</replaceable> is a single character string
	    containig a comma separated list of &ps; IDs. Depending on the
	    existence of the environment variable <envar>PSI_NODES_SORT</envar>
	    and the presence of the <option>-sort</option> option, the order of
	    the nodes within <replaceable>nodelist</replaceable> might be
	    relevant.
	  </para>
	  <para>
	    If the number of spawned processes exceeds the number of nodes
	    within the partition, some nodes may get more than one process.
	  </para>
	  <para>
	    If any of the environment variables <envar>PSI_NODES</envar>,
	    <envar>PSI_HOSTS</envar> or <envar>PSI_HOSTFILE</envar> is set,
	    this option must not be given.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-hosts <replaceable>hostlist</replaceable></option>
	</term>
	<listitem>
	  <para>Define the nodes which will build the partition of the &ps;
	    cluster used in order to spawn new processes.
	  </para>
	  <para>
	    <replaceable>hostlist</replaceable> is a single character string
	    containing a space separated list of hostnames. These have to be
	    resolvable in order to get the corresponding &ps; IDs. Depending on
	    the existence of the environment variable
	    <envar>PSI_NODES_SORT</envar> and the presence of the
	    <option>-sort</option> option, the order of the nodes within
	    <replaceable>hostlist</replaceable> might be relevant.
	  </para>
	  <para>
	    If the number of spawned processes exceeds the number of nodes
	    within the partition, some nodes may get more than one process.
	  </para>
	  <para>
	    If any of the environment variables <envar>PSI_NODES</envar>,
	    <envar>PSI_HOSTS</envar> or <envar>PSI_HOSTFILE</envar> is set,
	    this option must not be given.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-hostfile <replaceable>hostfile</replaceable></option>
	</term>
	<listitem>
	  <para>Define the nodes which will build the partition of the &ps;
	    cluster used in order to spawn new processes.
	  </para>
	  <para>
	    <replaceable>hostfile</replaceable> is the name of a file
	    containing a list of hostnames. These have to be resolvable in
	    order to get the corresponding &ps; IDs. The format of the file is
	    one hostname per line. Depending on the existence of the
	    environment variable <envar>PSI_NODES_SORT</envar> and the presence
	    of the <option>-sort</option> option, the ordering of the nodes
	    within the <replaceable>hostfile</replaceable> might be relevant.
	  </para>
	  <para>
	    If the number of spawned processes exceeds the number of nodes
	    within the partition, some nodes may get more than one process.
	  </para>
	  <para>
	    If any of the environment variables <envar>PSI_NODES</envar>,
	    <envar>PSI_HOSTS</envar> or <envar>PSI_HOSTFILE</envar> is set,
	    this option must not be given.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-sort <replaceable>mode</replaceable></option>
	</term>
	<listitem>
	  <para>Steer the sorting criterium which is used in order to bring the
	    nodes within a partition in an appropriate order. This order will
	    be used to spawn remote processes. The following values of
	    <replaceable>mode</replaceable> are recognized:
	  </para>
	  <variablelist>
	    <varlistentry>
	      <term>proc</term>
	      <listitem>
		<para>The nodes are sorted by the number of running &ps;
		  processes before new processes are spawned. This is the
		  default behavior.
		</para>
	      </listitem>
	    </varlistentry>
	    <varlistentry>
	      <term>load</term>
	      <listitem>
                <para>The nodes are sorted by load before new processes are
		  spawned. Therefore nodes with the least load are used first.
                </para>
                <para>
                  To be more specific, the load average over the last minute is
		  used as the sorting criterium.
                </para>
	      </listitem>
	    </varlistentry>
	    <varlistentry>
	      <term>proc+load</term>
	      <listitem>
                <para>The nodes are sorted corresponding to the sum of the 1
		  minute load and the number of running &ps; processes. This
		  will lead to fair load-balancing even if processes are
		  started without notification to the &ps; management facility.
                </para>
	      </listitem>
	    </varlistentry>
	    <varlistentry>
	      <term>none</term>
	      <listitem>
                <para>No sorting of nodes before new processes are spawned. The
		  nodes are used in a round robin fashion as they are set in
		  the <envar>PSI_NODES</envar>, <envar>PSI_HOSTS</envar> or
		  <envar>PSI_HOSTFILE</envar> environment variables or via the
		  corresponding <option>-nodes</option>,
		  <option>-hosts</option> or <option>-hostfile</option>
		  options.
                </para>
	      </listitem>
	    </varlistentry>
	  </variablelist>
	  <para>
	    If the environment variables <envar>PSI_NODES_SORT</envar> is set,
	    this option must not be given.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>-all-local</option>
        </term>
        <listitem>
          <para>Run all processes on the master node.</para>
	  <para>
	    Keep in mind that the masternode ist not necessarily the local
	    machine but, depending on the &ps; configuration and the options
	    and environment variables given, may be any machine within the &ps;
	    cluster. Nevertheless all processes building the parallel MPIch/P4
	    task will run on the same node of the &ps; cluster.
	  </para>
        </listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-inputdest <replaceable>dest</replaceable></option>
	</term>
	<listitem>
	  <para>Define the process which receives any input to the parallel
	    task. <replaceable>dest</replaceable> is an integer number in the
	    range from 0 to <replaceable>nodes</replaceable>-1, where
	    <replaceable>nodes</replaceable> is set by the <option>-np</option>
	    option.
	  </para>
	  <para>
	    The default is to send the input to the process with rank 0 within
	    the parallel task.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-sourceprintf</option>
	</term>
	<listitem>
	  <para>If this option is enabled, the logger will give information
	    about the source of the output produced, i.e. <quote>[id]:</quote>
	    will be prepended to any line of output, where id is the rank of
	    the printing process within the parallel task.
	  </para>
	  <para>
	    Usually the id coincides with the MPI-rank.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-rusage</option>
	</term>
	<listitem>
	  <para>When this option is given, the logger will print a notice about
	    the user and system time consumed by each process within the
	    parallel task upon exit of this process.</para>
	</listitem>
      </varlistentry>
      <varlistentry>
	<term>
	  <option>-exports <replaceable>envlist</replaceable></option>
	</term>
	<listitem>
          <para>Register a list of environment variables which should be
	    exported to remote processes during spawning. Some environment
	    variables (<envar>HOME</envar>, <envar>USER</envar>,
	    <envar>SHELL</envar> and <envar>TERM</envar>) are exported by
	    default.
          </para>
          <para>
            Furthermore <envar>PWD</envar> is set correctly for remote
	    processes.
          </para>
	  <para>
	    <replaceable>envlist</replaceable> is a single character string
	    containing a comma separated list of environment variables. Only
	    the name of the environment variable has to be given.
          </para>
	  <para>
	    If the environment variable <envar>PSI_EXPORTS</envar> is set,
	    <replaceable>envlist</replaceable> will be appended to this
	    variable.
	  </para>
	</listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>-keep_pg</option> <option>, -leave_pg</option>
        </term>
        <listitem>
          <para>Don't remove the process group file which steers the startup of
	    the parallel MPIch/P4 task.
          </para>
          <para>
	    This file will be constructed on the fly during startup by the
	    <command>mpirun_chp4</command> program. The content of this file
	    will depend on the configuration of the &ps; cluster, the options
	    given to the <command>mpirun_chp4</command> and the environment
	    variables set.
	  </para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>-V</option> <option>, --version</option>
        </term>
        <listitem>
          <para>Output version information and exit.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>-v</option> <option>, --verbose</option>
        </term>
        <listitem>
          <para>Verbose execution with many message during startup of the
	    parallel task.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>-?</option> <option>, --help</option>
        </term>
        <listitem>
          <para>Show a help message.</para>
        </listitem>
      </varlistentry>
      <varlistentry>
        <term>
          <option>--usage</option>
        </term>
        <listitem>
          <para>Display a brief usage message.</para>
        </listitem>
      </varlistentry>
    </variablelist>
  </refsect1>

  <refsect1>
    <title>Examples</title>
    <para>
      In order to start the parallel MPIch/P4 program
      <filename>prog1</filename> on any 5 nodes within the &ps; cluster,
      execute:
    </para>
    <programlisting>	mpirun_chp4 -np 5 prog1 -v</programlisting>
    <para>
      The option <option>-v</option> will be passed to any instance of
      <filename>prog1</filename> spawned.
    </para>
    <para>
      If the parallel task should run on the nodes 5-9 of the cluster,
    </para>
    <programlisting>	mpirun_chp4 -np 5 -nodes "5,6,7,8,9" prog1</programlisting>
    <para>
      has to be executed.
    </para>
    <para>
      If the nodes should be sorted by load, use:
    </para>
    <programlisting>	mpirun_chp4 -np 5 -nodes "5,6,7,8,9" -sort load prog1</programlisting>
    <para>
      In order to acquire information about the user and system time used by
      the spawned processes on the different nodes run:
    </para>
    <programlisting>	mpirun_chp4 -np 5 -rusage prog1</programlisting>
  </refsect1>

  <refsect1>
    <title>Errors</title>
    <para>
      No known errors.
    </para>
  </refsect1>

  <refsect1>
    <title>See also</title>
    <para>
      <xref linkend="psmstart"/>, <xref linkend="environment"/>, <xref
	linkend="spawning"/>
    </para>
  </refsect1>

</refentry>
  <!-- Keep this comment at the end of the file
  Local variables:
  mode: xml
  sgml-omittag:nil
  sgml-shorttag:nil
  sgml-namecase-general:nil
  sgml-general-insert-case:lower
  sgml-minimize-attributes:nil
  sgml-always-quote-attributes:t
  sgml-indent-step:2
  sgml-indent-data:t
  sgml-parent-document:("userguide.xml" "book" "reference" "reference" ("title"))
  sgml-exposed-tags:nil
  sgml-local-catalogs:nil
  sgml-local-ecat-files:nil
  End:
  -->
